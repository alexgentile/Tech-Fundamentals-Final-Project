{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_file = 'data/train.csv'\n",
    "test_file = 'data/test.csv'\n",
    "\n",
    "train = pd.read_csv(train_file)\n",
    "test = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this makes the following row actually viewable\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing and Handling NA values\n",
    "We send the output to a csv because there are too many features to see properly in Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoolQC          1453\n",
       "MiscFeature     1406\n",
       "Alley           1369\n",
       "Fence           1179\n",
       "FireplaceQu      690\n",
       "LotFrontage      259\n",
       "GarageYrBlt       81\n",
       "GarageType        81\n",
       "GarageFinish      81\n",
       "GarageQual        81\n",
       "GarageCond        81\n",
       "BsmtFinType2      38\n",
       "BsmtExposure      38\n",
       "BsmtFinType1      37\n",
       "BsmtCond          37\n",
       "BsmtQual          37\n",
       "MasVnrArea         8\n",
       "MasVnrType         8\n",
       "Electrical         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to properly view which attributes have null values\n",
    "# train.isnull().sum().to_csv(\"nullvals.csv\")\n",
    "nullVals = train.isnull().sum()\n",
    "nullVals = nullVals[nullVals!=0].sort_values(ascending=False)\n",
    "nullVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoolQC          1456\n",
       "MiscFeature     1408\n",
       "Alley           1352\n",
       "Fence           1169\n",
       "FireplaceQu      730\n",
       "LotFrontage      227\n",
       "GarageYrBlt       78\n",
       "GarageCond        78\n",
       "GarageQual        78\n",
       "GarageFinish      78\n",
       "GarageType        76\n",
       "BsmtCond          45\n",
       "BsmtExposure      44\n",
       "BsmtQual          44\n",
       "BsmtFinType1      42\n",
       "BsmtFinType2      42\n",
       "MasVnrType        16\n",
       "MasVnrArea        15\n",
       "MSZoning           4\n",
       "BsmtFullBath       2\n",
       "BsmtHalfBath       2\n",
       "Utilities          2\n",
       "Functional         2\n",
       "Exterior2nd        1\n",
       "Exterior1st        1\n",
       "SaleType           1\n",
       "BsmtFinSF1         1\n",
       "BsmtFinSF2         1\n",
       "BsmtUnfSF          1\n",
       "KitchenQual        1\n",
       "GarageCars         1\n",
       "GarageArea         1\n",
       "TotalBsmtSF        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the test set also has null values that need to be handled.\n",
    "testNullVals = test.isnull().sum()\n",
    "testNullVals = testNullVals[testNullVals != 0].sort_values(ascending=False)\n",
    "testNullVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will combine the test and train datasets for the purposes of simplifying preprocessing. Their relative order will be \n",
    "# preserved to ensure they can be easily split up again after preprocessing\n",
    "\n",
    "# we need to append this column so the sale prices in the training data aren't dropped. We need to remove it later\n",
    "test['SalePrice'] = 0\n",
    "\n",
    "df = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoolQC          1456\n",
       "MiscFeature     1408\n",
       "Alley           1352\n",
       "Fence           1169\n",
       "FireplaceQu      730\n",
       "LotFrontage      227\n",
       "GarageYrBlt       78\n",
       "GarageCond        78\n",
       "GarageQual        78\n",
       "GarageFinish      78\n",
       "GarageType        76\n",
       "BsmtCond          45\n",
       "BsmtExposure      44\n",
       "BsmtQual          44\n",
       "BsmtFinType1      42\n",
       "BsmtFinType2      42\n",
       "MasVnrType        16\n",
       "MasVnrArea        15\n",
       "MSZoning           4\n",
       "BsmtFullBath       2\n",
       "BsmtHalfBath       2\n",
       "Utilities          2\n",
       "Functional         2\n",
       "Exterior2nd        1\n",
       "Exterior1st        1\n",
       "SaleType           1\n",
       "BsmtFinSF1         1\n",
       "BsmtFinSF2         1\n",
       "BsmtUnfSF          1\n",
       "KitchenQual        1\n",
       "GarageCars         1\n",
       "GarageArea         1\n",
       "TotalBsmtSF        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets examine the null values in both\n",
    "bothNull = test.isnull().sum()\n",
    "bothNull = bothNull[bothNull != 0].sort_values(ascending=False)\n",
    "bothNull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ex    4\n",
      "Gd    4\n",
      "Fa    2\n",
      "Name: PoolQC, dtype: int64\n",
      "\n",
      "0      2906\n",
      "561       1\n",
      "555       1\n",
      "519       1\n",
      "800       1\n",
      "738       1\n",
      "648       1\n",
      "576       1\n",
      "512       1\n",
      "480       1\n",
      "444       1\n",
      "368       1\n",
      "228       1\n",
      "144       1\n",
      "Name: PoolArea, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# viewing the values of the poolQC attribute\n",
    "print(df['PoolQC'].value_counts())\n",
    "\n",
    "print()\n",
    "# there is actually only 7 houses in the dataset with a pool (PoolArea > 0)\n",
    "print(df['PoolArea'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing NA to 'Na'\n",
    "\n",
    "# PoolQC\n",
    "df.loc[df['PoolQC'].isnull(), 'PoolQC'] = 'Na'\n",
    "\n",
    "# MiscFeature\n",
    "df.loc[df['MiscFeature'].isnull(), 'MiscFeature'] = 'Na'\n",
    "\n",
    "# Alley\n",
    "df.loc[df['Alley'].isnull(), 'Alley'] = 'Na'\n",
    "\n",
    "# Fence\n",
    "df.loc[df['Fence'].isnull(), 'Fence'] = 'Na'\n",
    "\n",
    "# FireplaceQu\n",
    "df.loc[df['FireplaceQu'].isnull(), 'FireplaceQu'] = 'Na'\n",
    "\n",
    "# GarageCond\n",
    "df.loc[df['GarageCond'].isnull(), 'GarageCond'] = 'Na'\n",
    "\n",
    "# GarageQual\n",
    "df.loc[df['GarageQual'].isnull(), 'GarageQual'] = 'Na'\n",
    "\n",
    "# GarageFinish\n",
    "df.loc[df['GarageFinish'].isnull(), 'GarageFinish'] = 'Na'\n",
    "\n",
    "# GarageType\n",
    "df.loc[df['GarageType'].isnull(), 'GarageType'] = 'Na'\n",
    "\n",
    "# BsmtExposure\n",
    "df.loc[df['BsmtExposure'].isnull(), 'BsmtExposure'] = 'Na'\n",
    "\n",
    "# BsmtCond\n",
    "df.loc[df['BsmtCond'].isnull(), 'BsmtCond'] = 'Na'\n",
    "\n",
    "# BsmtQual\n",
    "df.loc[df['BsmtQual'].isnull(), 'BsmtQual'] = 'Na'\n",
    "\n",
    "# BsmtFinType1\n",
    "df.loc[df['BsmtFinType1'].isnull(), 'BsmtFinType1'] = 'Na'\n",
    "\n",
    "# BsmtFinType2\n",
    "df.loc[df['BsmtFinType2'].isnull(), 'BsmtFinType2'] = 'Na'\n",
    "\n",
    "# MasVnrType\n",
    "df.loc[df['MasVnrType'].isnull(), 'MasVnrType'] = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for missing numeric values that we can set to 0\n",
    "\n",
    "# MasVnrArea\n",
    "df.loc[df['MasVnrArea'].isnull(), 'MasVnrArea'] = 0\n",
    "\n",
    "# BsmtFinSF1\n",
    "df.loc[df['BsmtFinSF1'].isnull(), 'BsmtFinSF1'] = 0\n",
    "\n",
    "# BsmtFinSF2\n",
    "df.loc[df['BsmtFinSF2'].isnull(), 'BsmtFinSF2'] = 0\n",
    "\n",
    "# BsmtUnfSF\n",
    "df.loc[df['BsmtUnfSF'].isnull(), 'BsmtUnfSF'] = 0\n",
    "\n",
    "# GarageCars\n",
    "df.loc[df['GarageCars'].isnull(), 'GarageCars'] = 0\n",
    "\n",
    "# GarageArea\n",
    "df.loc[df['GarageArea'].isnull(), 'GarageArea'] = 0\n",
    "\n",
    "# TotalBsmtSF\n",
    "df.loc[df['TotalBsmtSF'].isnull(), 'TotalBsmtSF'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities has 3 values that are not 'AllPub', and 2 of which are NA. The last one is only in the train set so it is\n",
    "# unable to help with any predictions. We can just drop the entire column because the attrbute is irrevelent\n",
    "\n",
    "df = df.drop(columns=['Utilities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have LotFrontage be the mean of the column\n",
    "\n",
    "df['LotFrontage'].fillna(df['LotFrontage'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rest have no valid na value so we set it to the most frequent class\n",
    "\n",
    "df = df.fillna(df.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now to check that the NA values are all gone\n",
    "nullCheck = df.isnull().sum()\n",
    "nullCheck = nullCheck[nullCheck!=0].sort_values(ascending=False)\n",
    "nullCheck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NA values have all been taken care of.\n",
    "\n",
    "### Feature Engineering\n",
    "Time to do some feature engineering. There are some numerical attributes that are actually categorical data, so we will change them to be strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will create features that combine other features in the dataset\n",
    "\n",
    "# total square footage (including finished basement area)\n",
    "df['TotalSF'] = df['GrLivArea'] + df['TotalBsmtSF'] - df['BsmtUnfSF']\n",
    "\n",
    "#  the total number of bathrooms, including the basement(counting half baths as .5 bathrooms and full baths as 1 bathroom)\n",
    "df['TotalBaths'] = df['FullBath'] + df['BsmtFullBath'] + 0.5 * (df['HalfBath'] + df['BsmtHalfBath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now for some numeric attributes that do not have a relevent ordering, so we make them categorical by making them strings\n",
    "\n",
    "df['MSSubClass'] = df['MSSubClass'].astype(str)\n",
    "df['MoSold'] = df['MoSold'].astype(str)\n",
    "df['YrSold'] = df['YrSold'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we create dummy variables\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redividing the Data\n",
    "\n",
    "We need to redivide the data back into the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = df[df['Id'] <= len(train)]\n",
    "test2 = df[df['Id'] > len(train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to drop the SalePrice column in the new test set\n",
    "\n",
    "test2 = test2.drop(columns=['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Outliers from the Training Set\n",
    "\n",
    "There are several outliers in the dataset, notably some very large houses (>4000 Square Feet) that sold for comparitively small amounts of money. These need to be removed to ensure they do not skew the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homes greater than 4000 Square Feet were filtered out.\n",
      "Homes which sold for greater than $350,000 were filtered out.\n"
     ]
    }
   ],
   "source": [
    "# the easiest way to filter out these houses is to remove all houses larger than 4000 SF\n",
    "\n",
    "train2.drop(train2[train2['GrLivArea'] > 4000].index, inplace=True)\n",
    "\n",
    "print('Homes greater than 4000 Square Feet were filtered out.')\n",
    "\n",
    "# when doing preliminary analysis, a box-and-whisker plot identified outliers in the sale price as being over approximately\n",
    "# $340,000. These houses were eliminated by filtering out all data points with a sale price greater than\n",
    "# Q3 + 1.5 * IQR = Q3 + 1.5 * (Q3-Q1)\n",
    "# where IQR is the Inter-Quartile Range, Q3 is the 75th Percentile of the data, and Q1 is the 25th Percentile of the data.\n",
    "# statistically, something is considered an outlier if it lies 1.5 times the interquartile range beyond the first \n",
    "# or third quartile in either direction.\n",
    "# in this case, there are no low-priced outliers so we only consider the upper outliers\n",
    "\n",
    "#Q3 = train2['SalePrice'].quantile(.75) # the 75th percentile of the sale price\n",
    "#Q1 = train2['SalePrice'].quantile(.25)\n",
    "\n",
    "#outlierThreshold = Q3 + 1.5 * (Q3 - Q1)\n",
    "\n",
    "#train2.drop(train2[train2['SalePrice'] > outlierThreshold].index, inplace=True)\n",
    "\n",
    "#print(f'Homes which sold for more than ${outlierThreshold} were filtered out')\n",
    "\n",
    "# initially, the commented out code above found I should be filtering out values greater than $340,150, but using that value \n",
    "# as opposed to $350,000 resulted in higher RMSLE by 0.015 on the best performing models (Lasso and XGBoost),\n",
    "# which is why I reverted back to using the $350,000 number.\n",
    "\n",
    "train2.drop(train2[train2['SalePrice'] > 350000].index, inplace=True)\n",
    "print('Homes which sold for greater than $350,000 were filtered out.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now export the new dataframes to csvs so they can be accessed in other notebooks\n",
    "train2File = 'data/train2.csv'\n",
    "test2File = 'data/test2.csv'\n",
    "train2.to_csv(train2File, index=False)\n",
    "test2.to_csv(test2File, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
