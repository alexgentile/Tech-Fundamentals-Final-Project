{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "The models are scored using the Root Mean Squared Logarithmic Error (RMSLE). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utilities import rmsle\n",
    "from utilities import gen_sub\n",
    "\n",
    "# the input files are train2 and test2 because they have been preprocessed\n",
    "trainFile = 'data/train2.csv'\n",
    "testFile = 'data/test2.csv'\n",
    "\n",
    "train = pd.read_csv(trainFile)\n",
    "test = pd.read_csv(testFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Model\n",
    "\n",
    "We begin with the Naive Model: we assume all houses are the mean house price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Model Score:  0.4075977724850718\n"
     ]
    }
   ],
   "source": [
    "naiveTrain_y = pd.read_csv(trainFile)\n",
    "naiveTrain_y['NaivePrediction'] = naiveTrain_y['SalePrice'].mean()\n",
    "\n",
    "naiveScore_train = rmsle(naiveTrain_y['NaivePrediction'], naiveTrain_y['SalePrice'])\n",
    "\n",
    "print(\"Naive Model Score: \", naiveScore_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now generate a submission using the test data and submit it to kaggle to see what the score is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveTest_y = pd.read_csv(testFile)\n",
    "naiveTest_y['NaivePrediction'] = naiveTrain_y['SalePrice'].mean()\n",
    "\n",
    "naive_sub = gen_sub(naiveTest_y, 'Id', 'NaivePrediction', filename='naive_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/Naive_Kaggle_submission.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the RMSLE on the Test set is .42949, which is not good, but it is better than many other submissions on kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A More Complex Model: Linear Regression\n",
    "\n",
    "We will now use a linear regression model and measure the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first generate a train_test split for evaluating the performance of the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_linear = train['SalePrice']\n",
    "\n",
    "X_linear = train.drop(columns=['SalePrice'])\n",
    "\n",
    "# we are using a train-test split of 70/30 to ensure enough data is used for training.\n",
    "# the actual test set is the same size as the training set\n",
    "X_linear_train, X_linear_test, y_linear_train, y_linear_test = train_test_split(X_linear, y_linear, \n",
    "                                                                                test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we train the model on the train split of the training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression()\n",
    "\n",
    "lm.fit(X_linear_train, y_linear_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model RMSLE for Validation Set:  0.20930156460471214\n"
     ]
    }
   ],
   "source": [
    "# now we generate predictions on the validation split of the training data and score the predictions\n",
    "#lm_train_pred = lm.predict(X_train)\n",
    "#lm_train_rmsle = rmsle(lm_train_pred, y_train)\n",
    "#print('Linear Model Loss for Training Set: ', lm_train_rmsle)\n",
    "\n",
    "lm_validate_pred = lm.predict(X_linear_test)\n",
    "lm_validate_rmsle = rmsle(lm_validate_pred, y_linear_test)\n",
    "print('Linear Model RMSLE for Validation Set: ', lm_validate_rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear model has a loss of about .20, which is about twice as good at the naive model, which had a loss of about .4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with Hand-Picked Features\n",
    "\n",
    "We will now try a linear regression using only a small subset of features, the features that I beileve to be the most important.\n",
    " - TotalSF\n",
    " - TotalBaths\n",
    " - LotArea\n",
    " - Neighborhood\n",
    " - OverallCond\n",
    " - OverallQual\n",
    " - SaleCondition\n",
    "   -  To catch forclosures, short sales, and sales between family members which would result in significantly lower prices than normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model with hand picked features\n",
    "most_important_features = ['TotalSF', 'TotalBaths', 'LotArea', \n",
    "                           'OverallCond', 'OverallQual']\n",
    "\n",
    "most_important_features.extend([i for i in list(train) if 'Neighborhood_' in i])\n",
    "most_important_features.extend([i for i in list(train) if 'SaleCondition_' in i])\n",
    "\n",
    "y_linear_hp = train['SalePrice']\n",
    "\n",
    "X_linear_hp = train[most_important_features]\n",
    "\n",
    "X_linear_hp_train, X_linear_hp_test, y_linear_hp_train, y_linear_hp_test = train_test_split(X_linear_hp, y_linear_hp,\n",
    "                                                                                           test_size=.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_hp = LinearRegression()\n",
    "\n",
    "lm_hp.fit(X_linear_hp_train, y_linear_hp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Model RMSLE for Hand-Picked attributes:  0.1903960060491247\n"
     ]
    }
   ],
   "source": [
    "lm_hp_validate_pred = lm_hp.predict(X_linear_hp_test)\n",
    "lm_hp_validate_rmsle = rmsle(lm_hp_validate_pred, y_linear_hp_test)\n",
    "print('Linear Model RMSLE for Hand-Picked attributes: ', lm_hp_validate_rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear Model with Hand-Picked attributes performed better than the Linear Model with all attributes, meaning many of the attributes affect the result more than others. For this reason, I predict a Lasso Model and a Boosted model will outperform both linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression\n",
    "\n",
    "The Lasso Regression model should select the most important metrics and ignore the least important metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "y_lasso = train['SalePrice']\n",
    "\n",
    "X_lasso = train.drop(columns=['SalePrice'])\n",
    "\n",
    "X_lasso_train, X_lasso_test, y_lasso_train, y_lasso_test = train_test_split(X_lasso, y_lasso,\n",
    "                                                                           test_size=.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the lasso model\n",
    "lasso = LassoCV(alphas=[17.5, 15, 10, 1, 0.1, 0.01, 0.001]).fit(X_lasso_train, y_lasso_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Model RMSLE:  0.16292682071890102\n"
     ]
    }
   ],
   "source": [
    "# get predictions and check accuracy\n",
    "lasso_validate_pred = lasso.predict(X_lasso_test)\n",
    "lasso_validate_rmsle = rmsle(lasso_validate_pred, y_lasso_test)\n",
    "print('Lasso Model RMSLE: ', lasso_validate_rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was able to get the Lasso RMSLE down to .163 using Hyper-parameter Tuning on the alpha values for the lasso model. This was not as low as I was expecting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosted Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "y_xgb = train['SalePrice']\n",
    "\n",
    "X_xgb = train.drop(columns=['SalePrice'])\n",
    "\n",
    "X_xgb_train, X_xgb_test, y_xgb_train, y_xgb_test = train_test_split(X_xgb, y_xgb,\n",
    "                                                                   test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "xgb_model.fit(X_xgb_train, y_xgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model RMSLE:  0.13109591135257523\n"
     ]
    }
   ],
   "source": [
    "# get predictions and find error\n",
    "xgb_validation_pred = xgb_model.predict(X_xgb_test)\n",
    "xgb_validation_rmsle = rmsle(xgb_validation_pred, y_xgb_test)\n",
    "print('XGBoost Model RMSLE: ', xgb_validation_rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boosted model performed the best of all the models tested, with a RMSLE of .131."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Kaggle submission for the xgboosted model\n",
    "xgb_test_pred = xgb_model.predict(test)\n",
    "xgb_sub = pd.DataFrame(test['Id'])\n",
    "xgb_sub['SalePrice'] = xgb_test_pred\n",
    "\n",
    "xgb_sub = gen_sub(xgb_sub, 'Id', 'SalePrice', filename='xgb_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/XGBoost_Model_Kaggle_Submission.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that this is a large improvement over previous submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
